
# Running the pipeline

The pipeline was written with snakemake: https://snakemake.readthedocs.io/en/stable/.

To get started, clone this repo and use it as a template. The following instructions assume you are in the repo directory.

## 1. Create the conda env

All the software used on the pipeline can be installed with conda,

Install conda if you dont already have: https://docs.conda.io/en/latest/

Create the env:
```bash
conda env create -n lcs -f conda.env.yaml
```

To run the analysis, make sure the env is active:
```bash
conda activate lcs
```

## 2. Markers source choice

The markers table contains the list of all mutation markers found in each of the variant-groups
defined in `data/variant-groups.tsv`.

You can either generate a new table or use a pre-generated one, note however 
if you want to change the variant-groups definition you will need to generate a new table.

Choose one of 3 options:

1. Generate a new table using [pango-designation](https://github.com/cov-lineages/pango-designation) as a source:

To do this you need to have a fasta file in `data/gisaid.fa.gz` containing all GISAID genomes
listed in the lineages.csv file from pango-designation repo.

You must register on the GISAID website to gain access to these sequences: https://www.gisaid.org/.

The variable `PANGO_DESIGNATIONS_VERSION` on `data/config.py`controls which version of pango-designation to use.

You can run `snakemake --config markers=pango-designation dataset=x repo -j1` to download the appropriate pango-designation repo to `data/pango-designation`

2. Generate a new table using [sequences tree generated by UCSC](https://hgdownload.soe.ucsc.edu/goldenPath/wuhCor1/UShER_SARS-CoV-2/) as a source:

This data, gathered by the [UShER](https://github.com/yatisht/usher) team, includes only public sequences, as such they are downloaded by the pipeline automatically.

The variable `PB_VERSION` on `data/config.py` controls which version of ucsc data to use.

3. Use a pre-generated table:

Pre-generated tables are provided to shorten the time required to run the pipeline, simply
choose which table you want to use and copy it to the appropriate place:

  1. pango-designation:
      `cp data/pre-generated-marker-tables/pango-designation-markers-v1.2.60.tsv outputs/variants_table/pango-markers-table.tsv`
  2. ucsc:
      `cp data/pre-generated-marker-tables/ucsc-markers-2021-08-19.tsv outputs/variants_table/ucsc-markers-table.tsv`

## 3. Prepare your pooled sample dataset

Place your pooled samples in `data/fastq`, and create a tags file listing your samples, it should look like this:
```bash
$ ls data/fastq/
sample1.fastq.gz
sample2.fastq.gz
sample3.fastq.gz

$ cat data/tags_pool_mypool
sample1
sample2
sample3
```

## 4. Run the pipeline

To execute the pipeline run the command:

`snakemake --config markers=pango dataset=mypool --cores <C> --resources mem_gb=<M>`

The `markers=x` config indicates which markers table you are using, `dataset=x` should match your tags file `data/tags_pool_x` describing your samples.

You also need to indicate how many cores and memory you have available to run the analysis, snakemake will parallelize the pipeline accordingly.

## 5. View the results

After the pipeline completes, the results should be in `outputs/decompose`,
checkout the `notebooks/` folder for examples of visualization of the results.
